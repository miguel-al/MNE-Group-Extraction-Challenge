{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNE Groups Data Extraction Challenge - MUR team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 2: ISIN and website search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from googlesearch import search\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file='config.yaml'):\n",
    "    \"\"\"\n",
    "    Loads configuration parameters from a YAML file.\n",
    "\n",
    "    Parameters:\n",
    "        config_file (str): The path to the YAML configuration file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the loaded configuration parameters.\n",
    "    \"\"\"\n",
    "    with open(config_file, 'r') as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "# --- Global Parameters from Config ---\n",
    "DATA_PATH = config['data_path']\n",
    "INPUT_FILENAME = config['input_filename']\n",
    "PAUSE_TIME_MIN = config['pause_time_min']\n",
    "PAUSE_TIME_MAX = config['pause_time_max']\n",
    "SEARCH_TIMEOUT = config['search_timeout']\n",
    "LONG_PAUSE_GROUPS_INTERVAL = config['long_pause_groups_interval']\n",
    "LONG_PAUSE_TIME = config['long_pause_time']\n",
    "OUTPUT_PHASE2 = config['output_phase2']\n",
    "PHASE1_PATTERN = config['phase1_pattern']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_isin(isin_code: str) -> bool:\n",
    "    \"\"\"\n",
    "    Verifies if a given string is a valid ISIN code, including the check digit calculation.\n",
    "\n",
    "    Parameters:\n",
    "        isin_code (str): The ISIN code to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the ISIN code is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(isin_code, str) or len(isin_code) != 12:\n",
    "        return False\n",
    "\n",
    "    isin_code_upper = isin_code.upper()\n",
    "    if not isin_code_upper[:2].isalpha() or not isin_code_upper[2:].isalnum() or not isin_code_upper[-1].isdigit():\n",
    "        return False\n",
    "\n",
    "    converted_digits = []\n",
    "    for char in isin_code_upper:\n",
    "        if '0' <= char <= '9':  \n",
    "            converted_digits.append(int(char))\n",
    "        elif 'A' <= char <= 'Z':\n",
    "            # Convert letters to numbers (A=10, B=11, ..., Z=35) and then split into digits\n",
    "            converted_digits.extend(divmod(ord(char) - ord('A') + 10, 10))\n",
    "        else:\n",
    "            return False \n",
    "\n",
    "    total_sum = 0\n",
    "    # Luhn algorithm: process from right to left\n",
    "    for i in range(len(converted_digits) - 1, -1, -1):\n",
    "        digit = converted_digits[i]\n",
    "        if (len(converted_digits) - 1 - i) % 2 == 1:\n",
    "            doubled_digit = digit * 2\n",
    "            if doubled_digit > 9:\n",
    "                total_sum += (doubled_digit % 10) + (doubled_digit // 10)\n",
    "            else:\n",
    "                total_sum += doubled_digit\n",
    "        else:\n",
    "            total_sum += digit\n",
    "    return total_sum % 10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_isin(name: str, max_results: int = 10, timeout: int = SEARCH_TIMEOUT) -> tuple:\n",
    "    \"\"\"\n",
    "    Searches for the ISIN of a company using Google Search.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name of the company to search for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the ISIN (str) if found, and the source (str).\n",
    "               Returns (None, None) if ISIN is not found.\n",
    "    \"\"\"\n",
    "    query = f\"{name} \" + \" OR \".join([\"isin\", \"stock\"])\n",
    "    pause_time = random.uniform(PAUSE_TIME_MIN, PAUSE_TIME_MAX)\n",
    "    time.sleep(pause_time)\n",
    "\n",
    "    try:\n",
    "        search_results = list(search(query, num_results=max_results))\n",
    "\n",
    "        for url in search_results:\n",
    "            try:\n",
    "                headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                                  \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "                }\n",
    "                response = requests.get(url, headers=headers, timeout=timeout)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                text = soup.get_text(separator=' ')\n",
    "\n",
    "                processed_text = re.sub(r'[^a-z0-9\\s]', ' ', text.lower())\n",
    "                isin_pattern = r'\\b([a-z]{2}[a-z0-9]{10})\\b'\n",
    "                match = re.search(isin_pattern, processed_text)\n",
    "\n",
    "                if match and check_isin(match.group(1)):\n",
    "                    found_isin = match.group(1).upper()\n",
    "                    return found_isin, url\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error getting URL {url} during ISIN search: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL {url} during ISIN search: {e}\")\n",
    "                continue\n",
    "        return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google search for ISIN '{name}': {e}\")\n",
    "        print(\"Waiting before retrying Google search...\")\n",
    "        time.sleep(LONG_PAUSE_TIME)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the domain name from a URL.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The input URL.\n",
    "\n",
    "    Returns:\n",
    "        str: The domain name (netloc), or an empty string if the URL is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return urlparse(url).netloc\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_website(name: str, max_results: int = 10, timeout: int = SEARCH_TIMEOUT) -> tuple:\n",
    "    \"\"\"\n",
    "    Searches for the official website of a company using Google Search.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name of the company to search for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the website URL (str) if found, and the source (str).\n",
    "               Returns (None, None) if website is not found.\n",
    "    \"\"\"\n",
    "    query = f\"{name} official website\"\n",
    "    pause_time = random.uniform(PAUSE_TIME_MIN, PAUSE_TIME_MAX)\n",
    "    time.sleep(pause_time)\n",
    "\n",
    "    try:\n",
    "        search_results = list(search(query, num_results=1))\n",
    "\n",
    "        url = search_results[0]\n",
    "        domain = get_domain(url)\n",
    "        if domain:\n",
    "            return domain, url\n",
    "        else:\n",
    "            return url, url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google search for website '{name}': {e}\")\n",
    "        print(\"Waiting before retrying Google search...\")\n",
    "        time.sleep(LONG_PAUSE_TIME)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load base and phase 1 output ===\n",
    "df_base = pd.read_csv(os.path.join(DATA_PATH, INPUT_FILENAME), sep=\";\", keep_default_na=False)\n",
    "df_base = df_base.replace('', pd.NA)\n",
    "\n",
    "phase1_files = [\n",
    "    os.path.join(DATA_PATH, f)\n",
    "    for f in os.listdir(DATA_PATH)\n",
    "    if f.startswith(PHASE1_PATTERN)\n",
    "]\n",
    "df_phase1 = pd.concat([pd.read_csv(f, sep=\";\", keep_default_na=False) for f in phase1_files], ignore_index=True)\n",
    "df_phase1 = df_phase1.replace('', pd.NA)\n",
    "\n",
    "# === Combine phase 1 and base ===\n",
    "df_combined = df_base.merge(\n",
    "    df_phase1[[\"ID\", \"NAME\", \"VARIABLE\", \"SRC\", \"VALUE\", \"CURRENCY\", \"REFYEAR\"]],\n",
    "    on=[\"ID\", \"NAME\", \"VARIABLE\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_new\")\n",
    ")\n",
    "\n",
    "for col in [\"SRC\", \"VALUE\", \"CURRENCY\", \"REFYEAR\"]:\n",
    "    df_combined[col] = df_combined[col].combine_first(df_combined[f\"{col}_new\"])\n",
    "    df_combined.drop(columns=[f\"{col}_new\"], inplace=True)\n",
    "\n",
    "# === Filter COUNTRY and WEBSITE entries without VALUE ===\n",
    "mask_missing = (\n",
    "    ((df_combined[\"VARIABLE\"] == \"COUNTRY\") | (df_combined[\"VARIABLE\"] == \"WEBSITE\")) &\n",
    "    (df_combined[\"VALUE\"].isna() | (df_combined[\"VALUE\"] == \"\"))\n",
    ")\n",
    "df_missing = df_combined[mask_missing].copy()\n",
    "df_missing[\"VALUE\"] = \"\"\n",
    "df_missing[\"SRC\"] = \"\"\n",
    "df_missing[\"REFYEAR\"] = \"\"\n",
    "\n",
    "# === Process missing entries ===\n",
    "for i, row in df_missing.iterrows():\n",
    "    name = row[\"NAME\"]\n",
    "    variable = row[\"VARIABLE\"]\n",
    "    print(f\"Searching {variable} for: {name}\")\n",
    "    try:\n",
    "        if variable == \"COUNTRY\":\n",
    "            isin, src = search_isin(name)\n",
    "            if isin:\n",
    "                df_missing.at[i, \"VALUE\"] = isin[:2]\n",
    "                df_missing.at[i, \"SRC\"] = src\n",
    "                df_missing.at[i, \"REFYEAR\"] = 2024\n",
    "        elif variable == \"WEBSITE\":\n",
    "            website, src = search_website(name)\n",
    "            if website:\n",
    "                df_missing.at[i, \"VALUE\"] = website\n",
    "                df_missing.at[i, \"SRC\"] = src\n",
    "                df_missing.at[i, \"REFYEAR\"] = 2024\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name} ({variable}): {e}\")\n",
    "        continue\n",
    "\n",
    "# === Integrate phase 2 results into the base dataframe ===\n",
    "for i, row in df_missing.iterrows():\n",
    "    cond = (\n",
    "        (df_combined[\"ID\"] == row[\"ID\"]) &\n",
    "        (df_combined[\"VARIABLE\"] == row[\"VARIABLE\"]) &\n",
    "        ((df_combined[\"VALUE\"].isna()) | (df_combined[\"VALUE\"] == \"\"))\n",
    "    )\n",
    "    df_combined.loc[cond, [\"VALUE\", \"SRC\", \"REFYEAR\"]] = row[[\"VALUE\", \"SRC\", \"REFYEAR\"]].values\n",
    "\n",
    "# === Save final combined output ===\n",
    "df_combined.to_csv(os.path.join(DATA_PATH, OUTPUT_PHASE2), sep=\";\", index=False)\n",
    "print(f\"Final results saved to {OUTPUT_PHASE2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
